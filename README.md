# DVC Lab 

A hands-on lab project demonstrating **Data Version Control (DVC)** integrated with **Google Cloud Storage (GCS)** for versioning datasets in a machine learning project. This lab uses a **Chipotle stores dataset** as the tracked data asset.

---

##  Overview

This project covers:
- Setting up DVC with Google Cloud Storage as a remote backend
- Tracking and versioning a CSV dataset using DVC
- Pushing and pulling data to/from GCS
- Handling dataset updates with automatic hash tracking
- Reverting to previous dataset versions using Git + DVC

---

##  Prerequisites

- Python 3.8+
- Git
- A Google Cloud Platform (GCP) account with a project created
- A GCS bucket (region: `us-east1`)
- A GCP Service Account with **Owner** role and its credentials downloaded as a JSON key file

---

##  Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/kavin1317/dvc-lab.git
cd dvc-lab
```

### 2. Create and Activate a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate        # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ☁️ Google Cloud Storage Setup

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new GCS bucket in region **us-east1**
3. Navigate to **IAM & Admin → Service Accounts** and create a new service account with the **Owner** role
4. Under **Manage Keys**, generate and download a JSON key file — this is your authentication credential

---

##  DVC Configuration

### Initialize DVC

```bash
dvc init
```

### Add GCS as the DVC Remote

```bash
dvc remote add -d myremote gs://<your-bucket-name>
```

### Set GCP Credentials

```bash
dvc remote modify --local myremote credentialpath <path-to-your-json-key>.json
```

Your `.dvc/config` will look like:

```ini
[core]
    remote = myremote
['remote "myremote"']
    url = gs://<your-bucket-name>
```

---

##  Tracking Data with DVC

### 1. Add the dataset to the `data/` folder

Place your Chipotle stores CSV file in the `data/` directory.

### 2. Track it with DVC

```bash
dvc add data/chipotle_stores.csv
```

### 3. Add DVC metadata files to Git

```bash
git add data/chipotle_stores.csv.dvc data/.gitignore
git commit -m "Track Chipotle stores dataset with DVC"
```

### 4. Push data to GCS

```bash
dvc push
```

---

##  Handling Dataset Updates

When your dataset changes:

```bash
# Replace the file in data/ with the updated version, then:
dvc add data/chipotle_stores.csv
git add data/chipotle_stores.csv.dvc
git commit -m "Update Chipotle stores dataset - new version"
dvc push
```

DVC automatically computes a new hash for the updated file and stores each version as a distinct object in GCS.

---

##  Reverting to a Previous Version

```bash
# Step 1: Checkout the Git commit with the desired dataset version
git checkout <commit-hash>

# Step 2: Restore the corresponding data using DVC
dvc checkout
```

DVC uses the stored hash in the `.dvc` file to fetch the exact dataset version from GCS.

---

##  Project Structure

```
dvc-lab/
├── .dvc/                          # DVC internal config and cache metadata
│   ├── config                     # Remote storage configuration
│   └── .gitignore
├── data/
│   ├── chipotle_stores.csv        # Dataset (tracked by DVC, not Git)
│   ├── chipotle_stores.csv.dvc    # DVC pointer file (tracked by Git)
│   └── .gitignore                 # Auto-generated by DVC
├── .dvcignore                     # Files/folders to ignore in DVC tracking
├── requirements.txt
└── README.md
```

---